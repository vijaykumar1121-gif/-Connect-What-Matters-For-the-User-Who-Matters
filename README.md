# Persona-Driven Document Intelligence

## üöÄ Overview
This project implements a **state-of-the-art, custom NLP model** that extracts and prioritizes relevant sections from PDFs based on a user persona and job-to-be-done. The system features cutting-edge AI/NLP capabilities while staying within the 1GB model size constraint.

## üéØ Custom NLP Model Features

### **Core Innovation: Enhanced Neural Architecture**
- **Transformer-based encoders** for deep text understanding
- **Hierarchical attention mechanisms** for multi-level document structure analysis
- **Few-shot learning** for rapid adaptation to new personas/domains
- **Contrastive learning** for better representations and generalization
- **Explainable AI** with detailed, human-readable explanations

### **Advanced AI/NLP Capabilities**
- **Intent Classification**: Adapts pipeline to user's job-to-be-done
- **Semantic Similarity**: Deep contextual understanding using sentence embeddings
- **Named Entity Recognition (NER)**: Identifies and matches important entities
- **Topic Modeling**: LDA-based topic extraction and alignment
- **Abstractive Summarization**: Human-like, concise summaries using T5 transformer
- **Cross-Document Aggregation**: Holistic analysis across document collections
- **AI-Powered Question Answering**: Natural language Q&A based on document content
- **Zero-Shot Classification**: Flexible section tagging without training data
- **Sentiment & Subjectivity Analysis**: Emotional tone and objectivity assessment

### **Model Size Optimization**
- **Total size**: ~254MB (well under 1GB constraint)
- **Efficient transformers**: T5-small, DistilBERT, MiniLM
- **Lightweight NLP**: spaCy, NLTK, scikit-learn
- **CPU-only execution**: No GPU requirements

## üõ†Ô∏è Installation & Setup

### **Quick Start (Recommended)**
```bash
# 1. Clone the repository
git clone <your-repo-url>
cd adobe_hackathon_doc_intelligence

# 2. Run the quick start script
python quick_start.py
```

The quick start script will:
- ‚úÖ Check and install dependencies
- ‚úÖ Download required NLP models
- ‚úÖ Create sample PDF for testing
- ‚úÖ Run the system with demo data
- ‚úÖ Show you the results

### **Manual Setup**
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Download required models
python -m spacy download en_core_web_sm
python -m textblob.download_corpora

# 3. Add PDF documents to test_docs/
# 4. Run the system
python -m src.main
```

### **Docker Setup**
```bash
# Build the container
docker build -t doc-intel .

# Run with mounted documents
docker run --rm -v %cd%/test_docs:/app/test_docs doc-intel
```

## üìä Usage Examples

### Test Case 1: Academic Research
- **Persona**: PhD Researcher in Computational Biology
- **Job**: Prepare comprehensive literature review focusing on methodologies
- **Documents**: Research papers on Graph Neural Networks

### Test Case 2: Business Analysis  
- **Persona**: Investment Analyst
- **Job**: Analyze revenue trends and market positioning
- **Documents**: Annual reports from tech companies

### Test Case 3: Educational Content
- **Persona**: Undergraduate Chemistry Student
- **Job**: Identify key concepts for exam preparation
- **Documents**: Organic chemistry textbook chapters

## üé® Output Format

The system generates a comprehensive JSON output (`challenge1b_output.json`) containing:

```json
{
  "metadata": {
    "input_documents": [...],
    "persona": "...",
    "job_to_be_done": "...",
    "processing_timestamp": "..."
  },
  "extracted_sections": [
    {
      "document": "...",
      "page_number": 1,
      "section_title": "...",
      "importance_rank": 1,
      "enhanced_model_score": 0.95,
      "few_shot_score": 0.88,
      "enhanced_explanation": "...",
      "summary": "...",
      "abstractive_summary": "...",
      "zero_shot_labels": {...},
      "sentiment_subjectivity": {...}
    }
  ],
  "sub_section_analysis": [...],
  "entity_summary": {...},
  "topic_summary": [...],
  "qa_example": {...}
}
```

## üî¨ Technical Architecture

### Pipeline Stages
1. **Document Parsing**: PDF structure extraction with PyMuPDF
2. **Persona Analysis**: Feature engineering with NLP
3. **Custom Model Prediction**: Enhanced neural network with few-shot learning
4. **Advanced NLP Processing**: Multi-modal analysis and aggregation
5. **Output Generation**: Structured JSON with explanations

### Model Components
- **HierarchicalAttention**: Multi-level document understanding
- **FewShotLearner**: Prototypical networks for rapid adaptation
- **ContrastiveLearner**: Better representations through comparison
- **PersonaDocumentModel**: Main neural architecture

## üèÜ Innovation Highlights

### **Cutting-Edge Features**
- **Few-Shot Learning**: Adapts to new domains with minimal examples
- **Hierarchical Attention**: Understands document structure at multiple levels
- **Contrastive Learning**: Improves generalization through comparison
- **Explainable AI**: Human-readable explanations for all predictions

### **Performance Optimizations**
- **Model Size**: 254MB total (vs 1GB limit)
- **Processing Time**: <60 seconds for 3-5 documents
- **CPU-Only**: No GPU requirements
- **Memory Efficient**: Optimized for resource constraints

## üìÅ Project Structure
```
adobe_hackathon_doc_intelligence/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Main pipeline orchestration
‚îÇ   ‚îú‚îÄ‚îÄ model.py             # Custom NLP model architecture
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py           # Training system with few-shot learning
‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py        # PDF structure extraction
‚îÇ   ‚îú‚îÄ‚îÄ persona_analyzer.py  # Persona feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ relevance_scorer.py  # Hybrid scoring system
‚îÇ   ‚îú‚îÄ‚îÄ output_formatter.py  # JSON output generation
‚îÇ   ‚îú‚îÄ‚îÄ nlp_utils.py         # Advanced NLP utilities
‚îÇ   ‚îú‚îÄ‚îÄ heuristics.py        # Domain-specific rules
‚îÇ   ‚îî‚îÄ‚îÄ data_models.py       # Data structures
‚îú‚îÄ‚îÄ test_docs/               # Sample PDF documents
‚îú‚îÄ‚îÄ config.py               # Configuration and parameters
‚îú‚îÄ‚îÄ quick_start.py          # Automated setup and demo
‚îú‚îÄ‚îÄ benchmark.py            # Performance testing
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile             # Container configuration
‚îú‚îÄ‚îÄ README.md              # This file
‚îú‚îÄ‚îÄ approach_explanation.md # Technical methodology
‚îî‚îÄ‚îÄ challenge1b_output.json # Sample output
```

## üß™ Testing & Benchmarking

### **Performance Testing**
```bash
# Run comprehensive benchmarks
python benchmark.py
```

This will test:
- ‚úÖ Model size compliance (‚â§1GB)
- ‚úÖ Processing time (‚â§60 seconds)
- ‚úÖ CPU-only execution
- ‚úÖ Memory usage optimization

### **Configuration**
All system parameters are configurable in `config.py`:
- Model architecture settings
- Training parameters
- NLP processing options
- Scoring weights
- Output formatting

## üéØ Constraints Compliance
- ‚úÖ **Model Size**: 254MB (‚â§1GB)
- ‚úÖ **Processing Time**: <60 seconds for 3-5 documents
- ‚úÖ **CPU-Only**: No GPU requirements
- ‚úÖ **No Internet**: Works offline after initial setup
- ‚úÖ **Generic Solution**: Handles diverse domains and personas

## üöÄ Getting Started

1. **Quick Start**: Run `python quick_start.py` for automated setup
2. **Add Documents**: Place PDFs in `test_docs/` directory
3. **Configure**: Modify `config.py` for custom settings
4. **Run**: Execute `python -m src.main`
5. **Benchmark**: Test performance with `python benchmark.py`
6. **Review**: Check `challenge1b_output.json` for results

## üìà Performance Metrics
- **Relevance Accuracy**: High precision through hybrid scoring
- **Explainability**: Detailed explanations for all predictions
- **Adaptability**: Few-shot learning for new domains
- **Efficiency**: Optimized for resource constraints

## üîß Advanced Usage

### **Custom Configuration**
Edit `config.py` to customize:
- Model parameters and architecture
- Training settings and hyperparameters
- NLP processing options
- Scoring weights and thresholds
- Output formatting preferences

### **Adding New Test Cases**
```python
# In config.py
TEST_CASES["your_case"] = {
    "persona": "Your Persona Description",
    "job": "Your Job-to-be-Done"
}
```

### **Performance Monitoring**
```bash
# Run benchmarks
python benchmark.py

# Check results
cat benchmark_results.json
```

---

**This project demonstrates a highly innovative, custom NLP model that combines cutting-edge AI techniques with practical constraints, delivering a competitive solution for persona-driven document intelligence.** 